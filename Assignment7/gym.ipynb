{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7e4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808b50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c cogsci pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a131d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0b01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6860fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arg_parser():\n",
    "  parser = argparse.ArgumentParser(description='Run an environment')\n",
    "  parser.add_argument('--input-env', dest='input_env', required=True,\n",
    "  choices=['cartpole', 'mountaincar', 'pendulum', 'taxi', 'lake'], \n",
    "            help='Specify the name of the environment')\n",
    "  return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1938a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function and parse the input arguments,\n",
    "def run(input_env):\n",
    "    name_map = {'cartpole': 'CartPole-v1', \n",
    "                'mountaincar': 'MountainCar-v0',\n",
    "                'pendulum': 'Pendulum-v0',\n",
    "                'taxi': 'Taxi-v1',\n",
    "                'lake': 'FrozenLake-v0'}\n",
    "\n",
    "# Create a mapping from input argument string to the names of the environments as specified in the OpenAI Gym package,\n",
    " # Create the environment and reset it\n",
    "\n",
    "    env = gym.make(name_map[input_env])\n",
    "    env.reset()\n",
    "\n",
    "\n",
    "# Iterate 1000 times and take action during each step:\n",
    "    for _ in range(1000):\n",
    "      \n",
    "        env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb45719",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDL_VIDEODRIVER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mset_mode((\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m))\n\u001b[1;32m      5\u001b[0m run(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcartpole\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "import pygame\n",
    "pygame.display.set_mode((640,480))\n",
    "run(\"cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dddb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"mountaincar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arg_parser():\n",
    "    parser = argparse.ArgumentParser(description='Run an environment')\n",
    "    parser.add_argument('--input-env', dest='input_env', required=True,\n",
    "            choices=['cartpole', 'mountaincar', 'pendulum'], \n",
    "            help='Specify the name of the environment')\n",
    "    return parser\n",
    "\n",
    "def run(input_env):\n",
    "\n",
    "    name_map = {'cartpole': 'CartPole-v1', \n",
    "                'mountaincar': 'MountainCar-v0',\n",
    "                'pendulum': 'Pendulum-v0'}\n",
    "\n",
    "    env = gym.make(name_map[input_env])\n",
    " \n",
    "    for _ in range(20):\n",
    "        observation = env.reset()\n",
    "\n",
    "        for i in range(100):\n",
    "            env.render()\n",
    "\n",
    "            print(observation)\n",
    " \n",
    "            action = env.action_space.sample()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                print('Episode finished after {} timesteps'.format(i+1))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reward/link connection graph\n",
    "\n",
    "R = np.matrix([\n",
    "        [-1, -1, -1, -1, 0, -1],\n",
    "        [-1, -1, -1, 0, -1, 100],\n",
    "        [-1, -1, -1, 0, -1, -1],\n",
    "        [-1, 0, 0, -1, 0, -1],\n",
    "        [ 0, -1, -1, 0, -1, 100],\n",
    "        [-1, 0, -1, -1, 0, 100]\n",
    "]).astype(\"float32\")\n",
    "Q = np.zeros_like(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee85d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameter\n",
    "gamma = 0.8\n",
    "\n",
    "# Initialize random state\n",
    "initial_state = np.random.randint(0, 4)\n",
    "\n",
    "def available_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    av_act = np.where(current_state_row >= 0)[1]\n",
    "    return av_act\n",
    "\n",
    "def sample_next_action(available_actions_range):\n",
    "    next_action = int(np.random.choice(available_act,1))\n",
    "    return next_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(current_state, action, gamma):\n",
    "    # Update the Q matrix according to the path selected and the Q learning algorithm\n",
    "    max_index = np.where(Q[action,] == np.max(Q[action,]))[1]\n",
    "    if max_index.shape[0] > 1:\n",
    "        max_index = int(np.random.choice(max_index, size = 1))\n",
    "    else:\n",
    "        max_index = int(max_index)\n",
    "    max_value = Q[action, max_index]\n",
    "    \n",
    "    # Q learning formula\n",
    "    Q[current_state, action] = R[current_state, action] + gamma * max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available actions in the current state\n",
    "available_act = available_actions(initial_state)\n",
    "# Sample next action to be performed\n",
    "action = sample_next_action(available_act)\n",
    "# Train over 100 iterations, re-iterate the process above).\n",
    "for i in range(100):\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    available_act = available_actions(current_state)\n",
    "    action = sample_next_action(available_act)\n",
    "    update(current_state,action,gamma)\n",
    "# Normalize the \"trained\" Q matrix\n",
    "print (\"Trained Q matrix: \\n\", Q/np.max(Q)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a56c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_act = available_actions(initial_state)\n",
    "action = sample_next_action(available_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train over 100 iterations, re-iterate the process above).\n",
    "for i in range(100):\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    available_act = available_actions(current_state)\n",
    "    action = sample_next_action(available_act)\n",
    "    update(current_state, action, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the \"trained\" Q matrix\n",
    "print(\"Trained Q matrix: \\n\", Q/np.max(Q)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = 2\n",
    "steps = [current_state]\n",
    "\n",
    "while current_state != 5:\n",
    "    next_step_index = np.where(Q[current_state,] == np.max(Q[current_state,]))[1]\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index = int(np.random.choice(next_step_index, size=1))\n",
    "    else:\n",
    "        next_step_index = int(next_step_index)\n",
    "    steps.append(next_step_index)\n",
    "    current_state = next_step_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print selected sequence of steps\n",
    "print (f\"Best sequence path: {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ffd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
